---
---

@string{aps = {American Physical Society,}}

@article{mingxin2024isbi,
  abbr = {ISBI},
  author = {Liu, Mingxin and Liu, Yunzan and Xu, Pengbo and Ma, Jiquan},
  title = {Unleashing the Infinity Power of Geometry: A Novel Geometry-Aware Transformer (GOAT) for Whole Slide Histopathology Image Analysis},
  journal = {IEEE International Symposium on Biomedical Imaging (ISBI)},
  year = {2024},
  selected={true},
  abstract={The histopathology analysis is of great significance for the diagnosis and prognosis of cancers, however, it has great challenges due to the enormous heterogeneity of gigapixel whole slide images (WSIs) and the intricate representation of pathological features. However, recent methods have not adequately exploited geometrical representation in WSIs which is significant in disease diagnosis. Therefore, we proposed a novel weakly-supervised framework, \textbf{G}e\textbf{o}metry-\textbf{A}ware \textbf{T}ransformer (\textbf{GOAT}), in which we urge the model to pay attention to the geometric characteristics within the tumor microenvironment which often serve as potent indicators. In addition, a context-aware attention mechanism is designed to extract and enhance the morphological features within WSIs. Extensive experimental results demonstrated that the proposed method is capable of consistently reaching superior classification outcomes for gigapixel whole slide images.},
  pdf={https://arxiv.org/pdf/2402.05373.pdf},
  bibtex_show={true},
}

@article{mingxin2023bibm,
  abbr = {BIBM},
  author = {Liu, Mingxin and Liu, Yunzan and Cui, Hui and Li, Chunquan and Ma, Jiquan},
  title = {MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome Prediction using Integrative Histopathology-Genomic Features},
  journal = {IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  year = {2023},
  pages={1306--1312},
  selected={true},
  abstract={The rapidly emerging field of deep learning-based computational pathology has shown promising results in utilizing whole slide images (WSIs) to objectively prognosticate cancer patients. However, most prognostic methods are currently limited to either histopathology or genomics alone, which inevitably reduces their potential to accurately predict patient prognosis. Whereas integrating WSIs and genomic features presents three main challenges: (1) the enormous heterogeneity of gigapixel WSIs which can reach sizes as large as 150,000Ã—150,000 pixels; (2) the absence of a spatially corresponding relationship between histopathology images and genomic molecular data; and (3) the existing early, late, and intermediate multimodal feature fusion strategies struggle to capture the explicit interactions between WSIs and genomics. To ameliorate these issues, we propose the Mutual-Guided Cross-Modality Transformer (MGCT), a weakly-supervised, attention-based multimodal learning framework that can combine histology features and genomic features to model the genotype-phenotype interactions within the tumor microenvironment. To validate the effectiveness of MGCT, we conduct experiments using nearly 3,600 gigapixel WSIs across five different cancer types sourced from The Cancer Genome Atlas (TCGA). Extensive experimental results consistently emphasize that MGCT outperforms the state-of-the-art (SOTA) methods.},
  pdf={https://ieeexplore.ieee.org/abstract/document/10385897},
  code={https://github.com/lmxmercy/MGCT},
  bibtex_show={true},
}
